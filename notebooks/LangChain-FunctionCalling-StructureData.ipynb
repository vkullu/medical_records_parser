{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Own your health app!\n",
    "\n",
    "Trying to show a simple PoC where I give it a medical test document and then ask \n",
    "some structured responses from it. \n",
    "\n",
    "For our real app, we will have 10's or 100's of such documents per individual \n",
    "and each document could be 10's to 100's of pages. This is because someone's diagnostic \n",
    "journey e.g. cancer is spread across tests and visits to 100's of institutions before they\n",
    "get refered to a large cancer center oncologist and this oncology team has to make sense of all you have\n",
    "endured {treatment, outcomes, discharge summaries} to give you the right next treatment when \n",
    "you arrive at their doorstep.\n",
    "\n",
    "\n",
    "For now success will be if for a single report I am able to get back all the\n",
    "diagnostic tests done without missing. It tends to miss a few and on repeated nudging since \n",
    "I know the answer, pull out more and more tests missed previously.\n",
    "Also, as a bonus what I would really really like would be I ask a question with a schema \n",
    "and it returns *all* the elements in the same schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "# Right now this does not do directory, it takes one file at a time, could this be a limitation later !?!?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First approach is doing this with one big gulp, no splitting and using function calls to structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Core algorithm which parses the PDF file and structres the output.\n",
    "# the plus of using pedantic models is yo can force what you want the return obect to look like\n",
    "# pedantic then does the validation to make sure!\n",
    "# In the future we can make this configurable!\n",
    "\n",
    "#TODO: Adding a list object into the pedayntic object which itself is an object?\n",
    "\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chains.openai_functions.extraction import _get_extraction_function\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "\n",
    "doc = UnstructuredPDFLoader(file_path=\"/Users/vinayak/projects/medical_records_parser/data/MinnieMouseReport.pdf\")\n",
    "# Above I read the whole thing as ONE large blob, this was possible since the file is only 7 pages!\n",
    "# if the file becomes too large, this is not possible.\n",
    "docs = doc.load()\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "You are an expert medical transcriber. Please give me back a table of all the analytes measured. The table should have following columns: analyte_measured, result, reference_interval, unit, notes. \n",
    "If a patricular column does not exist please say NA.\n",
    "Please double check your work and do not miss any analyte.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Analyte(BaseModel):\n",
    "    \"\"\"Information about an analyte.\"\"\"\n",
    "    analyte_measured: str\n",
    "    result: str\n",
    "    reference_interval: str\n",
    "    unit: str\n",
    "    notes: str\n",
    "\n",
    "openai_function = _get_extraction_function(Analyte.schema())\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-16k\") #this approach will work as far as document size is small.\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", query),\n",
    "    (\"user\", \"{doc}\")\n",
    "])\n",
    "\n",
    "\n",
    "output_parser = JsonKeyOutputFunctionsParser(key_name=\"info\")\n",
    "chain = prompt | model.bind(functions=[openai_function], function_call={\"name\": \"information_extraction\"}) | output_parser\n",
    "\n",
    "response = chain.invoke({\"doc\": docs[0].page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analyte_measured</th>\n",
       "      <th>result</th>\n",
       "      <th>reference_interval</th>\n",
       "      <th>unit</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLOOD UREA NITROGEN</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0 - 17.0</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>METHOD : UREASE WITH INDICATOR DYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CREATININE, SERUM</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.52 - 1.04</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>METHOD : ENZYMETIC IDMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BUN/CREAT RATIO</td>\n",
       "      <td>11.29</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URIC ACID, SERUM</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5 - 6.2</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>METHOD : URICASE UV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOTAL PROTEIN, SERUM</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.3 - 8.30</td>\n",
       "      <td>g/dL</td>\n",
       "      <td>METHOD : BIURET, END POINT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ALBUMIN, SERUM</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.5 - 5.0</td>\n",
       "      <td>g/dL</td>\n",
       "      <td>METHOD : BCG DYE BINDING METHOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GLOBULIN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0 - 3.5</td>\n",
       "      <td>g/dL</td>\n",
       "      <td>METHOD : CALCULATED PARAMETER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SODIUM</td>\n",
       "      <td>139</td>\n",
       "      <td>137 - 145</td>\n",
       "      <td>mmol/L</td>\n",
       "      <td>METHOD : ION SELECTIVE ELECTRODE TECHNOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>POTASSIUM</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.6 - 5.0</td>\n",
       "      <td>mmol/L</td>\n",
       "      <td>METHOD : ION SELECTIVE ELECTRODE TECHNOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHLORIDE</td>\n",
       "      <td>107</td>\n",
       "      <td>98 - 107</td>\n",
       "      <td>mmol/L</td>\n",
       "      <td>METHOD : ION SELECTIVE ELECTRODE TECHNOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PH</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.7 - 7.5</td>\n",
       "      <td>NA</td>\n",
       "      <td>METHOD : DOUBLE INDICATOR PRINCIPLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PROTEIN</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NA</td>\n",
       "      <td>METHOD : TETRA BROMOPHENOL BLUE/SULFOSALICYLIC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GLUCOSE</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NA</td>\n",
       "      <td>METHOD : GLUCOSE OXIDASE PEROXIDASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KETONES</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NA</td>\n",
       "      <td>METHOD : NITROPRUSSIDE REACTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BLOOD</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NA</td>\n",
       "      <td>METHOD : PEROXIDASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>UROBILINOGEN</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NA</td>\n",
       "      <td>METHOD : MODIFIED EHRLICH REACTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NITRITE</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NA</td>\n",
       "      <td>METHOD : 1,2,3,4-TETRAHYDROBENZO(H)QUINOLIN-3-OL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LEUKOCYTE ESTERASE</td>\n",
       "      <td>DETECTED (+++)</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PUS CELL (WBC'S)</td>\n",
       "      <td>10-15</td>\n",
       "      <td>0-5</td>\n",
       "      <td>/HPF</td>\n",
       "      <td>METHOD : MICROSCOPIC EXAMINATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EPITHELIAL CELLS</td>\n",
       "      <td>5-7</td>\n",
       "      <td>0-5</td>\n",
       "      <td>/HPF</td>\n",
       "      <td>METHOD : MICROSCOPIC EXAMINATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ERYTHROCYTES (RBC'S)</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>/HPF</td>\n",
       "      <td>METHOD : MICROSCOPIC EXAMINATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CASTS</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>METHOD : MICROSCOPIC EXAMINATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CRYSTALS</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>METHOD : MICROSCOPIC EXAMINATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BACTERIA</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NA</td>\n",
       "      <td>METHOD : MICROSCOPIC EXAMINATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>YEAST</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NOT DETECTED</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HEMOGLOBIN</td>\n",
       "      <td>13.7</td>\n",
       "      <td>12.0 - 15.0</td>\n",
       "      <td>g/dL</td>\n",
       "      <td>METHOD : SLS- HEMOGLOBIN DETECTION METHOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RED BLOOD CELL COUNT</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.8 - 4.8</td>\n",
       "      <td>mil/µL</td>\n",
       "      <td>METHOD : HYDRODYNAMIC FOCUSING BY DC DETECTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>WHITE BLOOD CELL COUNT</td>\n",
       "      <td>9.72</td>\n",
       "      <td>4.0 - 10.0</td>\n",
       "      <td>thou/µL</td>\n",
       "      <td>METHOD : FLUORESCENCE FLOW CYTOMETRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PLATELET COUNT</td>\n",
       "      <td>283</td>\n",
       "      <td>150 - 410</td>\n",
       "      <td>thou/µL</td>\n",
       "      <td>METHOD : HYDRO DYNAMIC FOCUSING &amp; DC DETECTION...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>HEMATOCRIT</td>\n",
       "      <td>39.9</td>\n",
       "      <td>36.0 - 46.0</td>\n",
       "      <td>%</td>\n",
       "      <td>METHOD : CUMULATIVE PULSE HEIGHT DETECTION METHOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MEAN CORPUSCULAR VOLUME</td>\n",
       "      <td>89.3</td>\n",
       "      <td>83.0 - 101.0</td>\n",
       "      <td>fL</td>\n",
       "      <td>METHOD : CALCULATED FROM RBC &amp; HCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MEAN CORPUSCULAR HEMOGLOBIN</td>\n",
       "      <td>30.6</td>\n",
       "      <td>27.0 - 32.0</td>\n",
       "      <td>pg</td>\n",
       "      <td>METHOD : CALCULATED FROM RBC &amp; HCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MEAN CORPUSCULAR HEMOGLOBIN CONCENTRATION</td>\n",
       "      <td>34.3</td>\n",
       "      <td>31.5 - 34.5</td>\n",
       "      <td>g/dL</td>\n",
       "      <td>METHOD : CALCULATED FROM RBC &amp; HCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MENTZER INDEX</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RED CELL DISTRIBUTION WIDTH</td>\n",
       "      <td>12.5</td>\n",
       "      <td>11.6 - 14.0</td>\n",
       "      <td>%</td>\n",
       "      <td>METHOD : CALCULATED FROM RBC SIZE DISTRIBUTION...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MEAN PLATELET VOLUME</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.8 - 10.9</td>\n",
       "      <td>fL</td>\n",
       "      <td>METHOD : CALCULATED FROM PLATELET COUNT &amp; PLAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NEUTROPHILS</td>\n",
       "      <td>74</td>\n",
       "      <td>40.0 - 80.0</td>\n",
       "      <td>%</td>\n",
       "      <td>METHOD : FLOW CYTOMETRY WITH LIGHT SCATTERING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ABSOLUTE NEUTROPHIL COUNT</td>\n",
       "      <td>7.19</td>\n",
       "      <td>2.0 - 7.0</td>\n",
       "      <td>thou/µL</td>\n",
       "      <td>METHOD : FLOW CYTOMETRY WITH LIGHT SCATTERING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LYMPHOCYTES</td>\n",
       "      <td>20</td>\n",
       "      <td>20.0 - 40.0</td>\n",
       "      <td>%</td>\n",
       "      <td>METHOD : FLOW CYTOMETRY WITH LIGHT SCATTERING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ABSOLUTE LYMPHOCYTE COUNT</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.0 - 3.0</td>\n",
       "      <td>thou/µL</td>\n",
       "      <td>METHOD : FLOW CYTOMETRY WITH LIGHT SCATTERING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NEUTROPHIL LYMPHOCYTE RATIO (NLR)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>METHOD : CALCULATED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>EOSINOPHILS</td>\n",
       "      <td>1</td>\n",
       "      <td>1 - 6</td>\n",
       "      <td>%</td>\n",
       "      <td>METHOD : FLOW CYTOMETRY WITH LIGHT SCATTERING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ABSOLUTE EOSINOPHIL COUNT</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.02 - 0.50</td>\n",
       "      <td>thou/µL</td>\n",
       "      <td>METHOD : FLOW CYTOMETRY WITH LIGHT SCATTERING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>MONOCYTES</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0 - 10.0</td>\n",
       "      <td>%</td>\n",
       "      <td>METHOD : FLOW CYTOMETRY WITH LIGHT SCATTERING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ABSOLUTE MONOCYTE COUNT</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.2 - 1.0</td>\n",
       "      <td>thou/µL</td>\n",
       "      <td>METHOD : FLOW CYTOMETRY WITH LIGHT SCATTERING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>HEMOGLOBIN</td>\n",
       "      <td>13.7</td>\n",
       "      <td>12.0 - 15.0</td>\n",
       "      <td>g/dL</td>\n",
       "      <td>METHOD : SLS- HEMOGLOBIN DETECTION METHOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>BILIRUBIN, TOTAL</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.2 - 1.3</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>METHOD : DIPHYLLINE DIAZONIUM SALTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>BILIRUBIN, DIRECT</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0 - 0.3</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>METHOD : DIPHYLLINE DIAZONIUM SALTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>BILIRUBIN, INDIRECT</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0 - 1.1</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>METHOD : DIPHYLLINE DIAZONIUM SALTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>TOTAL PROTEIN</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.3 - 8.3</td>\n",
       "      <td>g/dL</td>\n",
       "      <td>METHOD : BIURET, END POINT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ALBUMIN</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.5 - 5.0</td>\n",
       "      <td>g/dL</td>\n",
       "      <td>METHOD : BCG DYE BINDING METHOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>GLOBULIN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0 - 3.5</td>\n",
       "      <td>g/dL</td>\n",
       "      <td>METHOD : CALCULATED PARAMETER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ASPARTATE AMINOTRANSFERASE (AST/SGOT)</td>\n",
       "      <td>35</td>\n",
       "      <td>14 - 36</td>\n",
       "      <td>U/L</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ALANINE AMINOTRANSFERASE (ALT/SGPT)</td>\n",
       "      <td>27</td>\n",
       "      <td>&lt; 35.0</td>\n",
       "      <td>U/L</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ALKALINE PHOSPHATASE</td>\n",
       "      <td>87</td>\n",
       "      <td>38 - 126</td>\n",
       "      <td>U/L</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>GAMMA GLUTAMYL TRANSFERASE (GGT)</td>\n",
       "      <td>25</td>\n",
       "      <td>12 - 43</td>\n",
       "      <td>U/L</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>LACTATE DEHYDROGENASE</td>\n",
       "      <td>172</td>\n",
       "      <td>120 - 246</td>\n",
       "      <td>U/L</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             analyte_measured          result  \\\n",
       "0                         BLOOD UREA NITROGEN               7   \n",
       "1                           CREATININE, SERUM            0.62   \n",
       "2                             BUN/CREAT RATIO           11.29   \n",
       "3                            URIC ACID, SERUM             4.5   \n",
       "4                        TOTAL PROTEIN, SERUM             6.4   \n",
       "5                              ALBUMIN, SERUM             2.9   \n",
       "6                                    GLOBULIN             3.5   \n",
       "7                                      SODIUM             139   \n",
       "8                                   POTASSIUM            3.40   \n",
       "9                                    CHLORIDE             107   \n",
       "10                                         PH             5.5   \n",
       "11                                    PROTEIN    NOT DETECTED   \n",
       "12                                    GLUCOSE    NOT DETECTED   \n",
       "13                                    KETONES    NOT DETECTED   \n",
       "14                                      BLOOD    NOT DETECTED   \n",
       "15                               UROBILINOGEN          NORMAL   \n",
       "16                                    NITRITE    NOT DETECTED   \n",
       "17                         LEUKOCYTE ESTERASE  DETECTED (+++)   \n",
       "18                           PUS CELL (WBC'S)           10-15   \n",
       "19                           EPITHELIAL CELLS             5-7   \n",
       "20                       ERYTHROCYTES (RBC'S)    NOT DETECTED   \n",
       "21                                      CASTS    NOT DETECTED   \n",
       "22                                   CRYSTALS    NOT DETECTED   \n",
       "23                                   BACTERIA    NOT DETECTED   \n",
       "24                                      YEAST    NOT DETECTED   \n",
       "25                                 HEMOGLOBIN            13.7   \n",
       "26                       RED BLOOD CELL COUNT            4.47   \n",
       "27                     WHITE BLOOD CELL COUNT            9.72   \n",
       "28                             PLATELET COUNT             283   \n",
       "29                                 HEMATOCRIT            39.9   \n",
       "30                    MEAN CORPUSCULAR VOLUME            89.3   \n",
       "31                MEAN CORPUSCULAR HEMOGLOBIN            30.6   \n",
       "32  MEAN CORPUSCULAR HEMOGLOBIN CONCENTRATION            34.3   \n",
       "33                              MENTZER INDEX            20.0   \n",
       "34                RED CELL DISTRIBUTION WIDTH            12.5   \n",
       "35                       MEAN PLATELET VOLUME            10.0   \n",
       "36                                NEUTROPHILS              74   \n",
       "37                  ABSOLUTE NEUTROPHIL COUNT            7.19   \n",
       "38                                LYMPHOCYTES              20   \n",
       "39                  ABSOLUTE LYMPHOCYTE COUNT            1.94   \n",
       "40          NEUTROPHIL LYMPHOCYTE RATIO (NLR)             3.7   \n",
       "41                                EOSINOPHILS               1   \n",
       "42                  ABSOLUTE EOSINOPHIL COUNT            0.10   \n",
       "43                                  MONOCYTES               5   \n",
       "44                    ABSOLUTE MONOCYTE COUNT            0.49   \n",
       "45                                 HEMOGLOBIN            13.7   \n",
       "46                           BILIRUBIN, TOTAL            2.07   \n",
       "47                          BILIRUBIN, DIRECT            0.20   \n",
       "48                        BILIRUBIN, INDIRECT            1.87   \n",
       "49                              TOTAL PROTEIN             6.4   \n",
       "50                                    ALBUMIN             2.9   \n",
       "51                                   GLOBULIN             3.5   \n",
       "52      ASPARTATE AMINOTRANSFERASE (AST/SGOT)              35   \n",
       "53        ALANINE AMINOTRANSFERASE (ALT/SGPT)              27   \n",
       "54                       ALKALINE PHOSPHATASE              87   \n",
       "55           GAMMA GLUTAMYL TRANSFERASE (GGT)              25   \n",
       "56                      LACTATE DEHYDROGENASE             172   \n",
       "\n",
       "   reference_interval     unit  \\\n",
       "0          7.0 - 17.0    mg/dL   \n",
       "1         0.52 - 1.04    mg/dL   \n",
       "2                  NA       NA   \n",
       "3           2.5 - 6.2    mg/dL   \n",
       "4          6.3 - 8.30     g/dL   \n",
       "5           3.5 - 5.0     g/dL   \n",
       "6           2.0 - 3.5     g/dL   \n",
       "7           137 - 145   mmol/L   \n",
       "8           3.6 - 5.0   mmol/L   \n",
       "9            98 - 107   mmol/L   \n",
       "10          4.7 - 7.5       NA   \n",
       "11       NOT DETECTED       NA   \n",
       "12       NOT DETECTED       NA   \n",
       "13       NOT DETECTED       NA   \n",
       "14       NOT DETECTED       NA   \n",
       "15             NORMAL       NA   \n",
       "16       NOT DETECTED       NA   \n",
       "17       NOT DETECTED       NA   \n",
       "18                0-5     /HPF   \n",
       "19                0-5     /HPF   \n",
       "20       NOT DETECTED     /HPF   \n",
       "21                 NA       NA   \n",
       "22                 NA       NA   \n",
       "23       NOT DETECTED       NA   \n",
       "24       NOT DETECTED       NA   \n",
       "25        12.0 - 15.0     g/dL   \n",
       "26          3.8 - 4.8   mil/µL   \n",
       "27         4.0 - 10.0  thou/µL   \n",
       "28          150 - 410  thou/µL   \n",
       "29        36.0 - 46.0        %   \n",
       "30       83.0 - 101.0       fL   \n",
       "31        27.0 - 32.0       pg   \n",
       "32        31.5 - 34.5     g/dL   \n",
       "33                 NA       NA   \n",
       "34        11.6 - 14.0        %   \n",
       "35         6.8 - 10.9       fL   \n",
       "36        40.0 - 80.0        %   \n",
       "37          2.0 - 7.0  thou/µL   \n",
       "38        20.0 - 40.0        %   \n",
       "39          1.0 - 3.0  thou/µL   \n",
       "40                 NA       NA   \n",
       "41              1 - 6        %   \n",
       "42        0.02 - 0.50  thou/µL   \n",
       "43         2.0 - 10.0        %   \n",
       "44          0.2 - 1.0  thou/µL   \n",
       "45        12.0 - 15.0     g/dL   \n",
       "46          0.2 - 1.3    mg/dL   \n",
       "47          0.0 - 0.3    mg/dL   \n",
       "48          0.0 - 1.1    mg/dL   \n",
       "49          6.3 - 8.3     g/dL   \n",
       "50          3.5 - 5.0     g/dL   \n",
       "51          2.0 - 3.5     g/dL   \n",
       "52            14 - 36      U/L   \n",
       "53             < 35.0      U/L   \n",
       "54           38 - 126      U/L   \n",
       "55            12 - 43      U/L   \n",
       "56          120 - 246      U/L   \n",
       "\n",
       "                                                notes  \n",
       "0                  METHOD : UREASE WITH INDICATOR DYE  \n",
       "1                             METHOD : ENZYMETIC IDMS  \n",
       "2                                                  NA  \n",
       "3                                 METHOD : URICASE UV  \n",
       "4                          METHOD : BIURET, END POINT  \n",
       "5                     METHOD : BCG DYE BINDING METHOD  \n",
       "6                       METHOD : CALCULATED PARAMETER  \n",
       "7         METHOD : ION SELECTIVE ELECTRODE TECHNOLOGY  \n",
       "8         METHOD : ION SELECTIVE ELECTRODE TECHNOLOGY  \n",
       "9         METHOD : ION SELECTIVE ELECTRODE TECHNOLOGY  \n",
       "10                METHOD : DOUBLE INDICATOR PRINCIPLE  \n",
       "11  METHOD : TETRA BROMOPHENOL BLUE/SULFOSALICYLIC...  \n",
       "12                METHOD : GLUCOSE OXIDASE PEROXIDASE  \n",
       "13                    METHOD : NITROPRUSSIDE REACTION  \n",
       "14                                METHOD : PEROXIDASE  \n",
       "15                 METHOD : MODIFIED EHRLICH REACTION  \n",
       "16   METHOD : 1,2,3,4-TETRAHYDROBENZO(H)QUINOLIN-3-OL  \n",
       "17                                                 NA  \n",
       "18                   METHOD : MICROSCOPIC EXAMINATION  \n",
       "19                   METHOD : MICROSCOPIC EXAMINATION  \n",
       "20                   METHOD : MICROSCOPIC EXAMINATION  \n",
       "21                   METHOD : MICROSCOPIC EXAMINATION  \n",
       "22                   METHOD : MICROSCOPIC EXAMINATION  \n",
       "23                   METHOD : MICROSCOPIC EXAMINATION  \n",
       "24                                                 NA  \n",
       "25          METHOD : SLS- HEMOGLOBIN DETECTION METHOD  \n",
       "26     METHOD : HYDRODYNAMIC FOCUSING BY DC DETECTION  \n",
       "27               METHOD : FLUORESCENCE FLOW CYTOMETRY  \n",
       "28  METHOD : HYDRO DYNAMIC FOCUSING & DC DETECTION...  \n",
       "29  METHOD : CUMULATIVE PULSE HEIGHT DETECTION METHOD  \n",
       "30                 METHOD : CALCULATED FROM RBC & HCT  \n",
       "31                 METHOD : CALCULATED FROM RBC & HCT  \n",
       "32                 METHOD : CALCULATED FROM RBC & HCT  \n",
       "33                                                 NA  \n",
       "34  METHOD : CALCULATED FROM RBC SIZE DISTRIBUTION...  \n",
       "35  METHOD : CALCULATED FROM PLATELET COUNT & PLAT...  \n",
       "36      METHOD : FLOW CYTOMETRY WITH LIGHT SCATTERING  \n",
       "37      METHOD : FLOW CYTOMETRY WITH LIGHT SCATTERING  \n",
       "38      METHOD : FLOW CYTOMETRY WITH LIGHT SCATTERING  \n",
       "39      METHOD : FLOW CYTOMETRY WITH LIGHT SCATTERING  \n",
       "40                                METHOD : CALCULATED  \n",
       "41      METHOD : FLOW CYTOMETRY WITH LIGHT SCATTERING  \n",
       "42      METHOD : FLOW CYTOMETRY WITH LIGHT SCATTERING  \n",
       "43      METHOD : FLOW CYTOMETRY WITH LIGHT SCATTERING  \n",
       "44      METHOD : FLOW CYTOMETRY WITH LIGHT SCATTERING  \n",
       "45          METHOD : SLS- HEMOGLOBIN DETECTION METHOD  \n",
       "46                METHOD : DIPHYLLINE DIAZONIUM SALTS  \n",
       "47                METHOD : DIPHYLLINE DIAZONIUM SALTS  \n",
       "48                METHOD : DIPHYLLINE DIAZONIUM SALTS  \n",
       "49                         METHOD : BIURET, END POINT  \n",
       "50                    METHOD : BCG DYE BINDING METHOD  \n",
       "51                      METHOD : CALCULATED PARAMETER  \n",
       "52                                                 NA  \n",
       "53                                                 NA  \n",
       "54                                                 NA  \n",
       "55                                                 NA  \n",
       "56                                                 NA  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(response) # Amit/Guy can you please see if the output is correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second approach is doing the same thing as above but one page at a time since sometimes the file might be too large to fit context size of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "doc = UnstructuredPDFLoader(file_path=\"/Users/vinayak/projects/medical_records_parser/data/MinnieMouseReport.pdf\", mode=\"paged\")\n",
    "# Above is the key difference where it is loading the data as \"paged\" mode.\n",
    "\n",
    "docs = doc.load()\n",
    "\n",
    "query = \"\"\"\n",
    "Please give me back a table of all the analytes measured. The table should have following columns: analyte_measured, result, reference_interval, unit, notes. \n",
    "If a patricular column does not exist please say NA.\n",
    "Please double check your work and do not miss any analyte.\n",
    "\"\"\"\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", query),\n",
    "    (\"user\", \"{doc}\")\n",
    "])\n",
    "\n",
    "# This is because of what _get_extraction_function does\n",
    "output_parser = JsonKeyOutputFunctionsParser(key_name=\"info\")\n",
    "\n",
    "chain = prompt | model.bind(functions=[openai_function], function_call={\"name\": \"information_extraction\"}) | output_parser\n",
    "\n",
    "\n",
    "responses = chain.batch([{\"doc\": d.page_content} for d in docs], {\"max_concurrency\": 5})\n",
    "\n",
    "extracted_by_function_call = []\n",
    "for response in responses:\n",
    "    extracted_by_function_call.extend(response)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(extracted_by_function_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now for the third approach, this is a VERY large document of 130+ pages including mishmash of diffrent kind of reports since it has come from an EMR dump (likely EPIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = UnstructuredPDFLoader(file_path=\"/Users/vinayak/projects/kaiser/data/Barbara/UCLA Health.pdf\")\n",
    "docs = doc.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing the entire contents of the document\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need some kind of splitter which closely resembles where records start and end\n",
    "# I am using the default on, which is sub optimal and does a lot of repeats and not so useful summarization too!\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(        \n",
    "    separator = \"\\n\\n\",\n",
    "    chunk_size = 10000,\n",
    "    chunk_overlap  = 500,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")\n",
    "\n",
    "doc = UnstructuredPDFLoader(\"/Users/vinayak/projects/kaiser/data/Barbara/UCLA Health.pdf\")\n",
    "\n",
    "docs = doc.load_and_split(text_splitter)\n",
    "\n",
    "print(\"Number of splits %d\"%(len(docs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice I also changed the question from parsing a diagnostic report to parsing medical visits. Likely we will have to do a hybrid where we first split the very large document into different pieces and for each piece parse what is relevant (diagnostic report vs visits vs pathology report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "You are an expert medical transcriber and can transcribe electronic health records with great skill.\n",
    "Please give me back a table of all the visits from the patient. Columns to return are:\n",
    "patient_name, date_of_visit, category, provider, institution, brief_summary\n",
    "The category can only be one of the following values: LAB_REPORT, PATHOLOGY, RADIOLOGY, PROCEDURE, DIAGNOSTIC_TEST, ROUTINE_VISIT\n",
    "If a patricular column does not exist please say NA.\n",
    "Please double check your work and do not miss any visits.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chains.openai_functions.extraction import _get_extraction_function\n",
    "\n",
    "class Visit(BaseModel):\n",
    "    \"\"\"Information about visit to the medical facility.\"\"\"\n",
    "    patient_name: str\n",
    "    date_of_visit: str\n",
    "    category: str\n",
    "    provider: str\n",
    "    institution: str\n",
    "    brief_summary: str\n",
    "\n",
    "openai_function = _get_extraction_function(Visit.schema())\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", query),\n",
    "    (\"user\", \"{doc}\")\n",
    "])\n",
    "\n",
    "chain = prompt | model.bind(functions=[openai_function], function_call={\"name\": \"information_extraction\"}) | output_parser\n",
    "\n",
    "# Make subset of docs below (8) so I don't become bankrupt! with openAI bills\n",
    "\n",
    "responses = chain.batch([{\"doc\": d.page_content} for d in docs], {\"max_concurrency\": 5})\n",
    "\n",
    "\n",
    "## The above code aks a question per subset of the data (according to the split which is 10k). This means it will have\n",
    "## answers per split. The response object is list of response, each response hiving a list of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to flatten the list\n",
    "\n",
    "flattened_list = list()\n",
    "for d in responses:\n",
    "    flattened_list.extend(d)\n",
    "\n",
    "flattened_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_records(flattened_list)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing cleanup to remove junk, this is because our parser is not yet good enough.\n",
    "\n",
    "df1 = df[(df.patient_name != 'NA')]\n",
    "df1 = df1[(df1.category != 'NA')]\n",
    "\n",
    "df1['date_cleanedup']= pd.to_datetime(df1['date_of_visit'], format='mixed')\n",
    "df1['final_date'] = df1['date_cleanedup'].apply(lambda x: x.strftime('%B %d, %Y'))\n",
    "\n",
    "df1.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)\n",
    "\n",
    "df1.sort_values(by='date_cleanedup').to_csv('/Users/vinayak/projects/df_to_test.tsv', sep=\"\\t\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns={'final_date': 'title','institution': 'cardTitle', 'category': 'cardSubtitle', 'brief_summary': 'cardDetailedText' }, inplace=True)\n",
    "cols_needed = ['title', 'cardTitle', 'cardSubtitle', 'cardDetailedText']\n",
    "df1[cols_needed].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now trying with GPT4 instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "You are an expert medical transcriber and can transcribe electronic health records with great skill.\n",
    "Please give me back a table of all the visits from the patient. Columns to return are:\n",
    "patient_name, date_of_visit, category, provider, institution, brief_summary\n",
    "The category can only be one of the following values: LAB_REPORT, PATHOLOGY, RADIOLOGY, PROCEDURE, DIAGNOSTIC_TEST, ROUTINE_VISIT\n",
    "If a patricular column does not exist please say NA.\n",
    "Please double check your work and do not miss any visits.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chains.openai_functions.extraction import _get_extraction_function\n",
    "\n",
    "class Visit(BaseModel):\n",
    "    \"\"\"Information about visit to the medical facility.\"\"\"\n",
    "    patient_name: str\n",
    "    date_of_visit: str\n",
    "    category: str\n",
    "    provider: str\n",
    "    institution: str\n",
    "    brief_summary: str\n",
    "\n",
    "openai_function = _get_extraction_function(Visit.schema())\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", query),\n",
    "    (\"user\", \"{doc}\")\n",
    "])\n",
    "\n",
    "chain = prompt | model.bind(functions=[openai_function], function_call={\"name\": \"information_extraction\"}) | output_parser\n",
    "\n",
    "# Make subset of docs below (8) so I don't become bankrupt! with openAI bills\n",
    "\n",
    "responses = chain.batch([{\"doc\": d.page_content} for d in docs], {\"max_concurrency\": 5})\n",
    "\n",
    "\n",
    "## The above code aks a question per subset of the data (according to the split which is 10k). This means it will have\n",
    "## answers per split. The response object is list of response, each response hiving a list of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to flatten the list\n",
    "\n",
    "flattened_list = list()\n",
    "for d in responses:\n",
    "    flattened_list.extend(d)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame.from_records(flattened_list)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[(df.patient_name != 'NA')]\n",
    "df1 = df1[(df1.category != 'NA')]\n",
    "\n",
    "df1['date_cleanedup']= pd.to_datetime(df1['date_of_visit'], format='mixed')\n",
    "df1['final_date'] = df1['date_cleanedup'].apply(lambda x: x.strftime('%B %d, %Y'))\n",
    "\n",
    "df1.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)\n",
    "\n",
    "df1.sort_values(by='date_cleanedup').to_csv('/Users/vinayak/projects/df_to_test_gpt4.tsv', sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is with Antropic Claudin2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "You are an expert medical transcriber and can transcribe electronic health records with great skill.\n",
    "Please give me back a table of all the visits from the patient. Columns to return are:\n",
    "patient_name, date_of_visit, category, provider, institution, brief_summary\n",
    "The category can only be one of the following values: LAB_REPORT, PATHOLOGY, RADIOLOGY, PROCEDURE, DIAGNOSTIC_TEST, ROUTINE_VISIT\n",
    "If a patricular column does not exist please say NA.\n",
    "Please double check your work and do not miss any visits.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chains.openai_functions.extraction import _get_extraction_function\n",
    "\n",
    "class Visit(BaseModel):\n",
    "    \"\"\"Information about visit to the medical facility.\"\"\"\n",
    "    patient_name: str\n",
    "    date_of_visit: str\n",
    "    category: str\n",
    "    provider: str\n",
    "    institution: str\n",
    "    brief_summary: str\n",
    "\n",
    "openai_function = _get_extraction_function(Visit.schema())\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "model = AnthropicFunctions(model='claude-2')\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", query),\n",
    "    (\"user\", \"{doc}\")\n",
    "])\n",
    "\n",
    "chain = prompt | model.bind(functions=[openai_function], function_call={\"name\": \"information_extraction\"}) | output_parser\n",
    "\n",
    "# Make subset of docs below (8) so I don't become bankrupt! with openAI bills\n",
    "\n",
    "responses = chain.batch([{\"doc\": d.page_content} for d in docs], {\"max_concurrency\": 5})\n",
    "\n",
    "\n",
    "## The above code aks a question per subset of the data (according to the split which is 10k). This means it will have\n",
    "## answers per split. The response object is list of response, each response hiving a list of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The stuff below is working but chunking is per page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "doc = UnstructuredPDFLoader(file_path=\"/Users/vinayak/projects/kaiser/data/Barbara/UCLA Health.pdf\", mode=\"paged\")\n",
    "\n",
    "docs = doc.load()\n",
    "\n",
    "query = \"\"\"\n",
    "Please give me back a table of all the visits from the patient. Columns to return are:\n",
    "visit_date, visit_reason, visit_department, visit_summary\n",
    "If a patricular column does not exist please say NA.\n",
    "Please double check your work and do not miss any visits.\n",
    "\"\"\"\n",
    "\n",
    "class Visit(BaseModel):\n",
    "    \"\"\"Information about visit to the medical facility.\"\"\"\n",
    "    visit_date: str\n",
    "    visit_reason: str\n",
    "    visit_department: str\n",
    "    visit_summary: str\n",
    "\n",
    "\n",
    "\n",
    "openai_function = _get_extraction_function(Visit.schema())\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", query),\n",
    "    (\"user\", \"{doc}\")\n",
    "])\n",
    "\n",
    "# This is because of what _get_extraction_function does\n",
    "output_parser = JsonKeyOutputFunctionsParser(key_name=\"info\")\n",
    "\n",
    "chain = prompt | model.bind(functions=[openai_function], function_call={\"name\": \"information_extraction\"}) | output_parser\n",
    "\n",
    "\n",
    "responses = chain.batch([{\"doc\": d.page_content} for d in docs], {\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mport sys\n",
    "from PyPDF2 import PdfFileReader, PdfFileWriter\n",
    "\n",
    "def edit_pdf_text(input_pdf_path, output_pdf_path, old_text, new_text):\n",
    "    # Read the existing PDF\n",
    "    with open(input_pdf_path, \"rb\") as file_handle:\n",
    "        pdf = PdfFileReader(file_handle)\n",
    "        content = pdf.getPage(0).extractText()\n",
    "\n",
    "    # Replace the old text with the new text\n",
    "    content = content.replace(old_text, new_text)\n",
    "\n",
    "    # Write the modified content to a new PDF\n",
    "    pdf_writer = PdfFileWriter()\n",
    "    pdf_writer.addPage(pdf.getPage(0))\n",
    "    with open(output_pdf_path, \"wb\") as output_pdf:\n",
    "        pdf_writer.write(output_pdf)\n",
    "        \n",
    "edit_pdf_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2 pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pdfplumber\n",
    "\n",
    "def replace_text_in_pdf(input_pdf_path, output_pdf_path, text_to_find, replacement_text):\n",
    "    with pdfplumber.open(input_pdf_path) as pdf:\n",
    "        pages = pdf.pages\n",
    "        #print(pages)\n",
    "        for i, page in enumerate(pages):\n",
    "            text = page.extract_text()\n",
    "            #print(text)\n",
    "            replaced_text = text.replace(\"Mouse\", \"Vinayak\")\n",
    "            pages[i] = replaced_text\n",
    "\n",
    "    with open(output_pdf_path, 'wb') as output_pdf:\n",
    "        pdf_writer = PyPDF2.PdfWriter()\n",
    "        for page in pages:\n",
    "            print(page)\n",
    "            pdf_writer.add_page(page)\n",
    "        pdf_writer.write('~/Desktop/Vinayak.pdf')\n",
    "        \n",
    "replace_text_in_pdf(input_pdf_path, output_pdf_path, 'Minnie', 'Vinayak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_text_in_pdf(input_pdf_path, output_pdf_path, 'Minnie', 'Vinayak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def change_text(pdf_file, old_text, new_text):\n",
    "  \"\"\"\n",
    "  This function changes the text in a PDF file.\n",
    "\n",
    "  Args:\n",
    "    pdf_file: The path to the PDF file.\n",
    "    old_text: The text to be replaced.\n",
    "    new_text: The new text.\n",
    "\n",
    "  Returns:\n",
    "    None.\n",
    "  \"\"\"\n",
    "\n",
    "  pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "  pdf_writer = PyPDF2.PdfWriter()\n",
    "\n",
    "  for page in pdf_reader.pages:\n",
    "    text = page.extract_text()\n",
    "    text = text.replace(old_text, new_text)\n",
    "    page.(text)\n",
    "\n",
    "  pdf_writer.write(pdf_file)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  pdf_file = input_pdf_path\n",
    "  old_text = \"This is the old text.\"\n",
    "  new_text = \"This is the new text.\"\n",
    "\n",
    "  change_text(pdf_file, old_text, new_text)\n",
    "\n",
    "  print(\"Text successfully changed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pdf_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install borb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!chapter_007/src/snippet_013.py\n",
    "from borb.pdf import Document\n",
    "from borb.pdf import PDF\n",
    "from borb.toolkit import SimpleFindReplace\n",
    "\n",
    "import typing\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # attempt to read a PDF\n",
    "    doc: typing.Optional[Document] = None\n",
    "    with open(input_pdf_path, \"rb\") as pdf_file_handle:\n",
    "        doc = PDF.loads(pdf_file_handle)\n",
    "\n",
    "    # check whether we actually read a PDF\n",
    "    assert doc is not None\n",
    "\n",
    "    # find/replace\n",
    "    doc = SimpleFindReplace.sub(\"Minnie\", \"Vinayak\", doc)\n",
    "\n",
    "    # store\n",
    "    with open(output_pdf_path, \"wb\") as pdf_file_handle:\n",
    "        PDF.dumps(pdf_file_handle, doc)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pdf_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pdfplumber\n",
    "\n",
    "def replace_text_in_pdf(input_pdf_path, output_pdf_path, text_to_find, replacement_text):\n",
    "    # Lists to hold the text content and their bounding boxes\n",
    "    replacements = []\n",
    "\n",
    "    # Extract text and their bounding boxes using pdfplumber\n",
    "    with pdfplumber.open(input_pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            for word in page.extract_words():\n",
    "                if text_to_find in word['text']:\n",
    "                    replaced_text = word['text'].replace(text_to_find, replacement_text)\n",
    "                    bbox = (word['x0'], word['y0'], word['x1'], word['y1'])\n",
    "                    replacements.append((replaced_text, bbox))\n",
    "\n",
    "    # Open the PDF with PyPDF2\n",
    "    with open(input_pdf_path, 'rb') as pdf_file:\n",
    "        reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "        writer = PyPDF2.PdfFileWriter()\n",
    "\n",
    "        for page_num in range(reader.numPages):\n",
    "            page = reader.getPage(page_num)\n",
    "\n",
    "            # Overlay the replacement texts\n",
    "            for text, bbox in replacements:\n",
    "                x0, y0, x1, y1 = bbox\n",
    "                # Adjust the coordinates as needed\n",
    "                page.merge_text(text, x0, y0, size=y1-y0)\n",
    "\n",
    "            writer.addPage(page)\n",
    "\n",
    "        # Write the modified content to the output PDF\n",
    "        with open(output_pdf_path, 'wb') as output_pdf:\n",
    "            writer.write(output_pdf)\n",
    "\n",
    "replace_text_in_pdf(input_pdf_path, '/Users/vinayak/Desktop/Vinaya.pdf', 'Mouse', 'Vinayak')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This section is trying to map a file to a type of report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "doc = UnstructuredPDFLoader(file_path=\"/Users/vinayak/projects/kaiser/data/barbara_split/ucla_1-6.pdf\")\n",
    "\n",
    "docs = doc.load()\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "You are an expert medical transcriber. Given a document you can clearly distinguish and categorize it.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_tagging_chain, create_tagging_chain_pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema\n",
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"aggressiveness\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"enum\": [1, 2, 3, 4, 5],\n",
    "            \"description\": \"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
    "        },\n",
    "        \"language\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"spanish\", \"english\", \"french\", \"german\", \"italian\"],\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"language\", \"sentiment\", \"aggressiveness\"],\n",
    "}\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
    "chain = create_tagging_chain(schema, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marvin import ai_classifier\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "@ai_classifier\n",
    "class ReportClassifer(Enum):\n",
    "    \"\"\"You are an expert clinican and medical notes interpreter. Classify the report based on which part of the healthcare network it came from\"\"\"\n",
    "\n",
    "    DIAGNOSTIC_REPORT = 1\n",
    "    OFFICE_VISIT = 2\n",
    "    SURGERY_VISIT = 3\n",
    "    RADIOLOGY_REPORT = 4\n",
    "    BLOOD_WORK = 5\n",
    "    MEDICATION_LIST = 6\n",
    "\n",
    "ReportClassifer(docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "doc = UnstructuredPDFLoader(file_path=\"/Users/vinayak/projects/kaiser/data/barbara_split/ucla_104-107.pdf\")\n",
    "\n",
    "docs = doc.load()\n",
    "\n",
    "ReportClassifer(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Trying summarization for the document\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
    "\n",
    "\n",
    "from langchain.document_loaders.image import UnstructuredImageLoader\n",
    "\n",
    "loader = UnstructuredImageLoader(\"/Users/vinayak/projects/kaiser/data/tcga_scanned_image/TCGA1.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='UUID: @CD23E1B\\n\\n\\n\\n3FA3\\n\\n\\n\\n4A43\\n\\n\\n\\nAEGE\\n\\n\\n\\naE O Sede\\n\\nName: Path No. : TCGA-3C-AAAU-@1A-PR Redacted MRN: Date Obtained: |If}] ATU TANNA O01 CT D.O.B. (Age: Date Received: HIN AAV A UT ATE AT Sex =F Physician: INNUINUIN INTO ARTA WT A Location: SURGICAL PATHOLOGY **See Addendum/Procedure** TODO. 3 SPECIMEN: - A:Lymph node, left axilla sentinel, biopsy Crrernorner, ol Dia t (obuda V sex20ls B:Breast, left, modified radical mastectomy o CE, (2, oN <y G504 = 5 SO YOuaat Lowe outer guadiaT CC® DIAGNOSIS(ES): aN | / , . » ) 6/ ISH A. Lymph node, left axilla sentinel, biopsy: > ~\\n\\nMetastatic carcinoma, following carcinoma of breast. B. Breast, left, modified radical mastectomy: 41. Carcinoma, invasive lobular, poorly differentiated, multifocal, with extensive lymphatic permeation and extension into nipple. 2. Lobular neoplasia, multifocal. 3. Fibrocystic disease, proliferative, with atypia. 4. Metastatic carcinoma in 3 of 12 axillary lymph nodes.\\n\\nDate Dictated:\\n\\nCLINICAL INFORMATION: Nore.\\n\\nGROSS DESCRIPTION: The specimen is received in two parts.\\n\\nPart A is received unfixed in a container labeled with the patient\\'s name and “sentinel node #1\". It consists of one piece of well circumscribed gritty tan tissue with attached fat measuring 1.2x1.0x0.6cm. It is bisected and a portion of it is submitted as AFS. The rest is submitted in one cassette labeled A1.\\n\\nPart B is received unfixed in a container labeled with the patient\\'s name and \"left breast mastectomy tissue\" consists of a left radical modified mastectomy specimen measuring 21x17x3 cm. The skin measures 9.5x5x0.1 cm and has a circumareolar scar which measures 4 cm in length. The nipple is mobile and everted. A firm area is palpable underneath the scar. The deep (fascial) margin is inked black, the remaining margins are inked yellow. The axillary tissue measures 9x5x1.2 ¢m. Several lymph nodes are palpable within it. One lymph node has been previously bisected by the surgeon. The lymph nodes range in size from 2.5 to 0.5 cm. They are dissected, proceeding from the axilla towards the breast. The specimen is serially sectioned at closely spaced intervals. Beneath the previously described scar is an ill-defined white, firm area which measures approximately 3.8x3.1x3 cm; it abuts the skin and is 3 cm from the deep margin. A second ill-defined white, firm area is present in the outer, lower quadrant approximately 1 cm from the central lesion; it measures approximately 2.5x2.3x1.8 cm and is located 0.5 cm from the deep margin and 14 cm from the superficial margin. At its center is a 1 cm firm area with a gelatinous appearance. The rest of the specimen is composed of 40% breast tissue, and 60% yellow fatty tissue. Representative sections are submitted in 40', metadata={'source': '/Users/vinayak/projects/kaiser/data/tcga_scanned_image/TCGA1.png'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loader.load()\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This document is a pathology report for a patient who underwent a left radical modified mastectomy. The specimen was received in two parts: Part A was a lymph node biopsy and Part B was the mastectomy specimen. The diagnosis for Part A was metastatic carcinoma following carcinoma of the breast. The diagnosis for Part B was invasive lobular carcinoma, lobular neoplasia, fibrocystic disease with atypia, and metastatic carcinoma in 3 of 12 axillary lymph nodes.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the summary of the document?\"\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The oncology report is for a patient who underwent a modified radical mastectomy of the left breast. The specimen was received in two parts: Part A was a sentinel node biopsy and Part B was the mastectomy tissue. The diagnosis was metastatic carcinoma following carcinoma of the breast, invasive lobular carcinoma, lobular neoplasia, fibrocystic disease with atypia, and metastatic carcinoma in 3 of 12 axillary lymph nodes.\\n\\nCitation: Part A is received unfixed in a container labeled with the patient\\'s name and “sentinel node #1\". It consists of one piece of well circumscribed gritty tan tissue with attached fat measuring 1.2x1.0x0.6cm. It is bisected and a portion of it is submitted as AFS. The rest is submitted in one cassette labeled A1. Part B is received unfixed in a container labeled with the patient\\'s name and \"left breast mastectomy tissue\" consists of a left radical modified mastectomy specimen measuring 21x17x3 cm. The skin measures 9.5x5x0.1 cm and has a circumareolar scar which measures 4 cm in length. The nipple is mobile and everted.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"Please give me a two part answer to my question. \n",
    "First, starting with Answer: is the answer to the question and second paragraph starting with Citation: the exact lines from the document used to give the answer\n",
    "What is the summary of this oncology report?\n",
    "\"\"\"\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The patient has metastatic carcinoma, following carcinoma of breast. This is stated in the Diagnosis(es) section: \"A. Lymph node, left axilla sentinel, biopsy: > ~ Metastatic carcinoma, following carcinoma of breast.\"'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What kind of cancer does the patient have? Please also provide the exact line from the document you used to answer the question\"\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Can I ask a question and get an answer back as a pydantic object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
