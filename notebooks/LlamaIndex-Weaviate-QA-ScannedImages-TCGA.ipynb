{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "import weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to your weaviate instance\n",
    "\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "\n",
    "client = weaviate.Client(\n",
    "  embedded_options=EmbeddedOptions()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alternative text](../docs/images/PXL_20230726_203549965.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data from a scanned path report image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surgery_image = SimpleDirectoryReader('/Users/vinayak/projects/kaiser/data/tcga_scanned_image/').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surgery_image\n",
    "# parsing has few issues as some of the text is garbled. e.g. date of birth is missing a slash, \n",
    "# tubule is parsed as Tuelle\n",
    "# score is also showing up as soce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk up the data posts into nodes \n",
    "parser = SimpleNodeParser()\n",
    "nodes = parser.get_nodes_from_documents(surgery_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores import WeaviateVectorStore\n",
    "from llama_index import VectorStoreIndex, StorageContext\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "\n",
    "\n",
    "# construct vector store\n",
    "vector_store = WeaviateVectorStore(weaviate_client = client, index_name=\"Surgery_Img_Scanned\", text_key=\"content\")\n",
    "\n",
    "# setting up the storage for the embeddings\n",
    "storage_context = StorageContext.from_defaults(vector_store = vector_store)\n",
    "#\n",
    "# set up the index\n",
    "index = VectorStoreIndex(nodes, storage_context = storage_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple one question answer ðŸš€\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Who is this report about? What is it about?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Larger extraction ðŸš€\n",
    "##   Trying to get semantic search by askign sex instead of gender\n",
    "###  Hoping it does NOT hallucinate when asked for something that does not exist!\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Please give me the patient name, age, sex, social security number, examining doctor, location, date of birth, height and report date. Please double check your work carefully. If any of these items are not present please say NA.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summazrize just the diagnosis ðŸš€\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is the diagnosis?\")\n",
    "print(response)\n",
    "\n",
    "\n",
    "## CONCERN: It missed some more details, picked up one amongst 3 other diagnosis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summazrize just the diagnosis ðŸš€\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Give me a detail of all the diagnosis in the document?\")\n",
    "print(response)\n",
    "\n",
    "## MILD CONCERN? Looks like now it got all the details and was able to reference \n",
    "## \"please see syntopic report\" and extract text from there as well.\n",
    "## However some of the words are garbled, e.g. Score is Soce?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if it is able to get specific Score parsed corectly? ðŸš€\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is the mitotic count score?\")\n",
    "print(response)\n",
    "\n",
    "## CONCERN: Not useful! Lie!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is another complementry approach using langchain and unstructured.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.image import UnstructuredImageLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredImageLoader(\"/Users/vinayak/projects/kaiser/data/surgery_image/surg_path.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n",
    "\n",
    "# This parsing seems much better, it does not have broken/garbled text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## At this point I don't know how to directly connect this to llama index to get its other goodies since the \n",
    "## two objects are incompatible. So I a doing the quicker hack, giving this parsed information directly to GPT to see what I get?\n",
    "\n",
    "\n",
    "## This one seems promising via llama hub: https://llamahub.ai/l/file-unstructured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_hub.file.unstructured.base import UnstructuredReader\n",
    "\n",
    "loader = UnstructuredReader()\n",
    "documents = loader.load_data(file='/Users/vinayak/projects/kaiser/data/tcga_scanned_image/TCGA4.png')\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk up the data posts into nodes \n",
    "parser = SimpleNodeParser()\n",
    "nodes = parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores import WeaviateVectorStore\n",
    "from llama_index import VectorStoreIndex, StorageContext\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "\n",
    "\n",
    "# construct vector store\n",
    "vector_store = WeaviateVectorStore(weaviate_client = client, index_name=\"TCGA_Img_Scanned_Unstructured\", text_key=\"content\")\n",
    "\n",
    "# setting up the storage for the embeddings\n",
    "storage_context = StorageContext.from_defaults(vector_store = vector_store)\n",
    "#\n",
    "# set up the index\n",
    "index = VectorStoreIndex(nodes, storage_context = storage_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summazrize just the diagnosis ðŸš€\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Is there a HIPAA discrepancy?\")\n",
    "print(response)\n",
    "\n",
    "##Parsed better but did not infer the connected extension like the previous case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summazrize just the diagnosis ðŸš€\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Give me a detail of all the diagnosis in the document? Please also include any references of additional details\")\n",
    "print(response)\n",
    "\n",
    "##Parsed better but did not infer the connected extension like the previous case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if it is able to get specific Score parsed correctly? ðŸš€\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is the mitotic count score?\")\n",
    "print(response)\n",
    "\n",
    "## That is much better, because it parsed better with unstructured model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.get_formatted_sources())\n",
    "\n",
    "## the fragment size is too large hence the whole thing comes up not just the short blurb.\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if it is able to get specific Score parsed correctly? ðŸš€\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is the mitotic count score? Also In a new line starting with word  Source: Give me the exact line which you used to give the answer.\")\n",
    "print(response)\n",
    "\n",
    "# this is surprising to me, the LLM does a better job at returning the source than the parser itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Larger extraction ðŸš€\n",
    "##   Trying to get semantic search by askign sex instead of gender\n",
    "###  Hoping it does NOT hallucinate when asked for something that does not exist!\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Please give me the patient name, age, sex, social security number, examining doctor, location, date of birth, height and report date. Please double check your work. If any of these items are not present please say NA. Also on a new line starting with # give the exact lines from the document you used to give the answer.\")\n",
    "print(response)\n",
    "\n",
    "## Better since it got the SSN and DOB without missing dashes and slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.source_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now mark the answer in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "def highlight_sentence(image_path, sentence):\n",
    "    # Load image with opencv\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to gray scale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform OCR using pytesseract\n",
    "    d = pytesseract.image_to_data(gray, output_type=pytesseract.Output.DICT)\n",
    "\n",
    "    # Zip together bounding box data\n",
    "    bounding_boxes = list(zip(d['left'], d['top'], d['width'], d['height'], d['text']))\n",
    "\n",
    "    # Convert sentence to lower case and split into words\n",
    "    sentence_words = sentence.lower().split()\n",
    "\n",
    "    # For storing the bounding box coordinates of the first and last word of the sentence\n",
    "    first_word, last_word = None, None\n",
    "    iter_words = iter(sentence_words)\n",
    "    current_word = next(iter_words)\n",
    "\n",
    "    for box in bounding_boxes:\n",
    "        left, top, width, height, text = box\n",
    "        if text.lower() == current_word:\n",
    "            # if this is the first word in sentence\n",
    "            if not first_word:\n",
    "                first_word = (left, top, width, height)\n",
    "            try:\n",
    "                # try to go to the next word\n",
    "                current_word = next(iter_words)\n",
    "            except StopIteration:\n",
    "                # If we're out of words, set this as the last box\n",
    "                last_word = (left, top, width, height)\n",
    "                break\n",
    "\n",
    "    # If we found a matching set of words, draw a rectangle around it\n",
    "    if first_word and last_word:\n",
    "        cv2.rectangle(img, (first_word[0], first_word[1]), (last_word[0] + last_word[2], last_word[1] + last_word[3]), (0, 255, 0), 2)\n",
    "\n",
    "    # Convert the image back to PIL image for better IO in python\n",
    "    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    return img_pil\n",
    "\n",
    "# Use the function\n",
    "image_path = \"/Users/vinayak/projects/kaiser/data/surgery_image/surg_path.jpeg\"\n",
    "sentence = 'Patient Name: DARROUGH, WINDY CAROLE'\n",
    "highlighted_img = highlight_sentence(image_path, sentence)\n",
    "highlighted_img.show()  # Display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is the name of the patient? Give me the exact line used to give me the answer on a seperate line.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Can you give me a three bullet point summary of key points in the document?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Can you give me a one line summary of the document?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# Open the image file\n",
    "img = Image.open('/Users/vinayak/Desktop/TCGA1.png')\n",
    "\n",
    "# Resize the image\n",
    "width, height = img.size\n",
    "img = img.resize((width*10, height*10), Image.BICUBIC)\n",
    "\n",
    "# Apply OCR to the image\n",
    "text = pytesseract.image_to_string(img)\n",
    "\n",
    "# Print the text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
